# df_agg$ind_res = as.factor(df_agg$median_res_8 > median(df_agg$median_res_8))
anyNA(df_agg)
# Bad dumb model 1
lm1 = lm(case_diff_7_8~population+mean_retail_7+mean_grocery_7+mean_parks_7+mean_transit_7+mean_work_7+mean_res_7,df_agg)
summary(lm1)
plot(lm1)
train.control = trainControl(method="cv",number=10)
step.model <- train(case_diff_7_8 ~ population + retail_diff_7_8 + grocery_diff_7_8 + parks_diff_7_8
+ transit_diff_7_8 + work_diff_7_8 + res_diff_7_8 + mean_retail_8 + mean_grocery_8
+ mean_parks_8 + mean_transit_8 + mean_work_8 + mean_res_8,
data = df_agg,
method = "leapBackward",
#tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, id=nrow(summary(step.model)$which))
# Save some stepwise objects for quick reference
stepwise = as.data.frame(summary(step.model)$which)
stepwise_names = tail(names(stepwise[,stepwise[nrow(stepwise),]==TRUE]),-1)
stepwise_formula = as.formula(paste('case_diff_7_8~',paste(stepwise_names,collapse="+"),sep=""))
stepwise_lm = lm(stepwise_formula,data=df_agg)
summary(stepwise_lm)
# Train experimental classifiers and check performance
set.seed(1)
train_experimental = trainControl(method="cv",number=10,classProbs=TRUE,savePredictions=TRUE)
experimental = train(high_growth_8 ~ population + retail_diff_7_8 + grocery_diff_7_8 + parks_diff_7_8
+ transit_diff_7_8 + work_diff_7_8 + res_diff_7_8 + mean_retail_8 + mean_grocery_8
+ mean_parks_8 + mean_transit_8 + mean_work_8 + mean_res_8,
data = df_agg,
method = 'glmStepAIC',
trControl = train_experimental
)
summary(experimental)
# Get confusion matrix stats
confusionMatrix(experimental)
precision = confusionMatrix(experimental)$table[2,2]/sum(confusionMatrix(experimental)$table[2,])
recall = confusionMatrix(experimental)$table[2,2]/sum(confusionMatrix(experimental)$table[,2])
precision;recall
# Get ROC stats
roc_curve = roc(experimental$pred$obs,experimental$pred$high_growth)
plot(roc_curve)
roc_curve$auc
# Get calibration stats
calibration = calibration(experimental$pred$obs~experimental$pred$high_growth,cuts=5,class='high_growth')
xyplot(calibration)
df_agg_OOT = df_subset_OOT %>%
mutate(month = month(date)) %>%
group_by(nation,state,county,location_combined,fips,month, population) %>%
summarise(#mean_pop = mean(population, na.rm=TRUE),
#med_pop = median(population, na.rm=TRUE),
end_cases = last(cases,order_by=date),
mean_cases = mean(cases, na.rm=TRUE),
median_cases = median(cases, na.rm=TRUE),
end_deaths = last(deaths,order_by=date),
mean_deaths = mean(deaths, na.rm=TRUE),
median_deaths = median(deaths, na.rm=TRUE),
mean_retail = mean(mobility_retail_recreation_change, na.rm=TRUE),
median_retail = median(mobility_retail_recreation_change, na.rm=TRUE),
mean_grocery = mean(mobility_grocery_pharmacy_change, na.rm=TRUE),
median_grocery = median(mobility_grocery_pharmacy_change, na.rm=TRUE),
mean_parks = mean(mobility_parks_change, na.rm=TRUE),
median_parks = median(mobility_parks_change, na.rm=TRUE),
mean_transit = mean(mobility_transit_stations_change, na.rm=TRUE),
median_transit = median(mobility_transit_stations_change, na.rm=TRUE),
mean_work = mean(mobility_workplaces_change, na.rm=TRUE),
median_work = median(mobility_workplaces_change, na.rm=TRUE),
mean_res = mean(mobility_residential_change, na.rm=TRUE),
median_res = median(mobility_residential_change, na.rm=TRUE)
) %>%
# mutate(end_cases = ifelse(is.na(end_cases),0,end_cases),
#        mean_cases = ifelse(is.na(mean_cases),0,mean_cases),
#        median_cases = ifelse(is.na(median_cases),0,median_cases),
#        end_deaths = ifelse(is.na(end_deaths),0,end_deaths),
#        mean_deaths = ifelse(is.na(mean_deaths),0,mean_deaths),
#        median_deaths = ifelse(is.na(median_deaths),0,median_deaths),
#        mean_retail = ifelse(is.na(mean_retail),0,mean_retail),
#        median_retail = ifelse(is.na(median_retail),0,median_retail),
#        mean_grocery = ifelse(is.na(mean_grocery),0,mean_grocery),
#        median_grocery = ifelse(is.na(median_grocery),0,median_grocery),
#        mean_parks = ifelse(is.na(mean_parks),0,mean_parks),
#        median_parks = ifelse(is.na(median_parks),0,median_parks),
#        mean_transit = ifelse(is.na(mean_transit),0,mean_transit),
#        median_transit = ifelse(is.na(median_transit),0,median_transit),
#        mean_work = ifelse(is.na(mean_work),0,mean_work),
#        median_work = ifelse(is.na(median_work),0,median_work),
#        mean_res = ifelse(is.na(mean_res),0,mean_res),
#        median_res = ifelse(is.na(median_res),0,median_res)
#        ) %>%
pivot_wider(id_cols=c("nation","state","county","location_combined","fips", "population"),
names_from=c("month"),
values_from=c(#"mean_pop", "med_pop",
"end_cases", "mean_cases", "median_cases", "end_deaths", "mean_deaths", "median_deaths",
"mean_retail", "median_retail", "mean_grocery", "median_grocery", "mean_parks", "median_parks", "mean_transit",
"median_transit", "mean_work", "median_work", "mean_res", "median_res")) %>%
na.omit() # drops count from 2766 to 2689. something to look into?
#should have named this something else, maybe, but renaming incorrectly just so predict function works easily.
df_agg_OOT$case_diff_7_8 = df_agg_OOT$end_cases_9/df_agg_OOT$end_cases_8 - 1
df_agg_OOT$case_diff_7_8[is.na(df_agg_OOT$case_diff_7_8)] = df_agg_OOT$end_cases_9[is.na(df_agg_OOT$case_diff_7_8)] - 1
# Hardcoded county median as response variable cutoff but could be an arbitrary value
cutoff = 0.3409769
df_agg_OOT$high_growth_8 = factor(ifelse(df_agg_OOT$case_diff_7_8 > cutoff,'high_growth','low_growth'))
df_agg_OOT$high_growth_8 = relevel(df_agg_OOT$high_growth_8,ref='low_growth')
df_agg_OOT$retail_diff_7_8 = (df_agg_OOT$median_retail_9 - df_agg_OOT$median_retail_8)
df_agg_OOT$grocery_diff_7_8 = (df_agg_OOT$median_grocery_9 - df_agg_OOT$median_grocery_8)
df_agg_OOT$parks_diff_7_8 = (df_agg_OOT$median_parks_9 - df_agg_OOT$median_parks_8)
df_agg_OOT$transit_diff_7_8 = (df_agg_OOT$median_transit_9 - df_agg_OOT$median_transit_8)
df_agg_OOT$work_diff_7_8 = (df_agg_OOT$median_work_9 - df_agg_OOT$median_work_8)
df_agg_OOT$res_diff_7_8 = (df_agg_OOT$median_res_9 - df_agg_OOT$median_res_8)
# df_agg$ind_retail = as.factor(df_agg$median_retail_8 > median(df_agg$median_retail_8))
# df_agg$ind_grocery = as.factor(df_agg$median_grocery_8 > median(df_agg$median_grocery_8))
# df_agg$ind_parks = as.factor(df_agg$median_parks_8 > median(df_agg$median_parks_8))
# df_agg$ind_transit = as.factor(df_agg$median_transit_8 > median(df_agg$median_transit_8))
# df_agg$ind_work = as.factor(df_agg$median_work_8 > median(df_agg$median_work_8))
# df_agg$ind_res = as.factor(df_agg$median_res_8 > median(df_agg$median_res_8))
anyNA(df_agg_OOT)
df_subset_OOT
tail(df_subset_OOT)
rm(list=ls())
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
if(!require(reshape2)){install.packages('reshape2');require(reshape2)}
if(basename(getwd())=="COVID-19"){df_Mobility = read.csv("./stats/2020_US_Region_Mobility_Report.csv")
df_COVID_conf_US = read.csv("./csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
df_COVID_death_US = read.csv("./csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")}
if(basename(getwd())=="stats"){df_Mobility = read.csv("../stats/2020_US_Region_Mobility_Report.csv")
df_COVID_conf_US = read.csv("../csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
df_COVID_death_US = read.csv("../csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")}
df_COVID_conf_US
df_COVID_conf_US_resh = melt(df_COVID_conf_US,id.vars=c("UID","iso2","iso3","code3","FIPS","Admin2","Province_State","Country_Region","Lat","Long_","Combined_Key"),na.rm=FALSE)
df_COVID_death_US_resh = melt(df_COVID_death_US,id.vars=c("UID","iso2","iso3","code3","FIPS","Admin2","Province_State","Country_Region","Lat","Long_","Combined_Key","Population"),na.rm=FALSE)
# Next step is to parse some dates in both tables for the join
# Parsing all dates as date_parsed, dropping raw date, renaming associated value
df_Mobility$date_parsed = as.Date(df_Mobility$date,format='%Y-%m-%d')
df_COVID_conf_US_resh$date_parsed = str_sub(str_replace_all(as.character(df_COVID_conf_US_resh$variable),'\\.','/'),start=2)
df_COVID_conf_US_resh$date_parsed = as.Date(df_COVID_conf_US_resh$date_parsed,format='%m/%d/%y')
df_COVID_conf_US_resh = subset(df_COVID_conf_US_resh,select=-variable)
names(df_COVID_conf_US_resh)[names(df_COVID_conf_US_resh)=="value"] = "cases"
df_COVID_death_US_resh$date_parsed = str_sub(str_replace_all(as.character(df_COVID_death_US_resh$variable),'\\.','/'),start=2)
df_COVID_death_US_resh$date_parsed = as.Date(df_COVID_death_US_resh$date_parsed,format='%m/%d/%y')
df_COVID_death_US_resh = subset(df_COVID_death_US_resh,select=-variable)
names(df_COVID_death_US_resh)[names(df_COVID_death_US_resh)=="value"] = "deaths"
# Joining all three tables using the 'conf' table as the base
# First join is between the time series DFs on all variables available since it's the same source
# The first inner join causes a loss of 2.3% of rows (small county diffs)
# Second join is between the new time series DF and the mobility DF on FIPS and Date
# The second inner join causes a loss of 17.6% (small county and time period diffs)
df_intermediate = inner_join(df_COVID_conf_US_resh,df_COVID_death_US_resh,na_matches='never')
df_intermediate$FIPS = as.character(df_intermediate$FIPS)
df_Mobility$census_fips_code = as.character(df_Mobility$census_fips_code)
df_merged = inner_join(df_intermediate,df_Mobility,by=c('date_parsed'='date_parsed',"FIPS"='census_fips_code'),na_matches='never')
# I'll select and rename columns for all further analysis while leaving the joined table alone
df_subset = subset(df_merged,
select=c(Country_Region,Province_State,Admin2,Combined_Key,FIPS,date_parsed,Population,cases,deaths,
retail_and_recreation_percent_change_from_baseline,grocery_and_pharmacy_percent_change_from_baseline,
parks_percent_change_from_baseline,transit_stations_percent_change_from_baseline,
workplaces_percent_change_from_baseline,residential_percent_change_from_baseline))
names(df_subset) = c('nation','state','county','location_combined','fips','date','population','cases','deaths',
'mobility_retail_recreation_change','mobility_grocery_pharmacy_change','mobility_parks_change',
'mobility_transit_stations_change','mobility_workplaces_change','mobility_residential_change')
df_subset_OOT = df_subset[df_subset['date'] > '2020-07-31',]
df_subset = df_subset[df_subset['date'] <= '2020-08-31',]
tail(df_subset_OOT
)
df_COVID_conf_US_resh
tail(df_COVID_conf_US_resh)
tail(df_Mobility)
rm(list=ls())
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
if(!require(reshape2)){install.packages('reshape2');require(reshape2)}
if(basename(getwd())=="COVID-19"){df_Mobility = read.csv("./stats/2020_US_Region_Mobility_Report.csv")
df_COVID_conf_US = read.csv("./csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
df_COVID_death_US = read.csv("./csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")}
if(basename(getwd())=="stats"){df_Mobility = read.csv("../stats/2020_US_Region_Mobility_Report.csv")
df_COVID_conf_US = read.csv("../csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
df_COVID_death_US = read.csv("../csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")}
tail(df_Mobility)
df_COVID_conf_US_resh = melt(df_COVID_conf_US,id.vars=c("UID","iso2","iso3","code3","FIPS","Admin2","Province_State","Country_Region","Lat","Long_","Combined_Key"),na.rm=FALSE)
df_COVID_death_US_resh = melt(df_COVID_death_US,id.vars=c("UID","iso2","iso3","code3","FIPS","Admin2","Province_State","Country_Region","Lat","Long_","Combined_Key","Population"),na.rm=FALSE)
# Next step is to parse some dates in both tables for the join
# Parsing all dates as date_parsed, dropping raw date, renaming associated value
df_Mobility$date_parsed = as.Date(df_Mobility$date,format='%Y-%m-%d')
df_COVID_conf_US_resh$date_parsed = str_sub(str_replace_all(as.character(df_COVID_conf_US_resh$variable),'\\.','/'),start=2)
df_COVID_conf_US_resh$date_parsed = as.Date(df_COVID_conf_US_resh$date_parsed,format='%m/%d/%y')
df_COVID_conf_US_resh = subset(df_COVID_conf_US_resh,select=-variable)
names(df_COVID_conf_US_resh)[names(df_COVID_conf_US_resh)=="value"] = "cases"
df_COVID_death_US_resh$date_parsed = str_sub(str_replace_all(as.character(df_COVID_death_US_resh$variable),'\\.','/'),start=2)
df_COVID_death_US_resh$date_parsed = as.Date(df_COVID_death_US_resh$date_parsed,format='%m/%d/%y')
df_COVID_death_US_resh = subset(df_COVID_death_US_resh,select=-variable)
names(df_COVID_death_US_resh)[names(df_COVID_death_US_resh)=="value"] = "deaths"
# Joining all three tables using the 'conf' table as the base
# First join is between the time series DFs on all variables available since it's the same source
# The first inner join causes a loss of 2.3% of rows (small county diffs)
# Second join is between the new time series DF and the mobility DF on FIPS and Date
# The second inner join causes a loss of 17.6% (small county and time period diffs)
df_intermediate = inner_join(df_COVID_conf_US_resh,df_COVID_death_US_resh,na_matches='never')
df_intermediate$FIPS = as.character(df_intermediate$FIPS)
df_Mobility$census_fips_code = as.character(df_Mobility$census_fips_code)
df_merged = inner_join(df_intermediate,df_Mobility,by=c('date_parsed'='date_parsed',"FIPS"='census_fips_code'),na_matches='never')
# I'll select and rename columns for all further analysis while leaving the joined table alone
df_subset = subset(df_merged,
select=c(Country_Region,Province_State,Admin2,Combined_Key,FIPS,date_parsed,Population,cases,deaths,
retail_and_recreation_percent_change_from_baseline,grocery_and_pharmacy_percent_change_from_baseline,
parks_percent_change_from_baseline,transit_stations_percent_change_from_baseline,
workplaces_percent_change_from_baseline,residential_percent_change_from_baseline))
names(df_subset) = c('nation','state','county','location_combined','fips','date','population','cases','deaths',
'mobility_retail_recreation_change','mobility_grocery_pharmacy_change','mobility_parks_change',
'mobility_transit_stations_change','mobility_workplaces_change','mobility_residential_change')
df_subset_OOT = df_subset[df_subset['date'] > '2020-07-31',]
df_subset = df_subset[df_subset['date'] <= '2020-08-31',]
tail(df_subset_OOT)
require(dplyr)
require(readr)
require(caret)
require(pROC)
require(PRROC)
require(lubridate)
require(leaps)
df_agg = df_subset %>%
mutate(month = month(date)) %>%
group_by(nation,state,county,location_combined,fips,month, population) %>%
summarise(#mean_pop = mean(population, na.rm=TRUE),
#med_pop = median(population, na.rm=TRUE),
end_cases = last(cases,order_by=date),
mean_cases = mean(cases, na.rm=TRUE),
median_cases = median(cases, na.rm=TRUE),
end_deaths = last(deaths,order_by=date),
mean_deaths = mean(deaths, na.rm=TRUE),
median_deaths = median(deaths, na.rm=TRUE),
mean_retail = mean(mobility_retail_recreation_change, na.rm=TRUE),
median_retail = median(mobility_retail_recreation_change, na.rm=TRUE),
mean_grocery = mean(mobility_grocery_pharmacy_change, na.rm=TRUE),
median_grocery = median(mobility_grocery_pharmacy_change, na.rm=TRUE),
mean_parks = mean(mobility_parks_change, na.rm=TRUE),
median_parks = median(mobility_parks_change, na.rm=TRUE),
mean_transit = mean(mobility_transit_stations_change, na.rm=TRUE),
median_transit = median(mobility_transit_stations_change, na.rm=TRUE),
mean_work = mean(mobility_workplaces_change, na.rm=TRUE),
median_work = median(mobility_workplaces_change, na.rm=TRUE),
mean_res = mean(mobility_residential_change, na.rm=TRUE),
median_res = median(mobility_residential_change, na.rm=TRUE)
) %>%
# mutate(end_cases = ifelse(is.na(end_cases),0,end_cases),
#        mean_cases = ifelse(is.na(mean_cases),0,mean_cases),
#        median_cases = ifelse(is.na(median_cases),0,median_cases),
#        end_deaths = ifelse(is.na(end_deaths),0,end_deaths),
#        mean_deaths = ifelse(is.na(mean_deaths),0,mean_deaths),
#        median_deaths = ifelse(is.na(median_deaths),0,median_deaths),
#        mean_retail = ifelse(is.na(mean_retail),0,mean_retail),
#        median_retail = ifelse(is.na(median_retail),0,median_retail),
#        mean_grocery = ifelse(is.na(mean_grocery),0,mean_grocery),
#        median_grocery = ifelse(is.na(median_grocery),0,median_grocery),
#        mean_parks = ifelse(is.na(mean_parks),0,mean_parks),
#        median_parks = ifelse(is.na(median_parks),0,median_parks),
#        mean_transit = ifelse(is.na(mean_transit),0,mean_transit),
#        median_transit = ifelse(is.na(median_transit),0,median_transit),
#        mean_work = ifelse(is.na(mean_work),0,mean_work),
#        median_work = ifelse(is.na(median_work),0,median_work),
#        mean_res = ifelse(is.na(mean_res),0,mean_res),
#        median_res = ifelse(is.na(median_res),0,median_res)
#        ) %>%
pivot_wider(id_cols=c("nation","state","county","location_combined","fips", "population"),
names_from=c("month"),
values_from=c(#"mean_pop", "med_pop",
"end_cases", "mean_cases", "median_cases", "end_deaths", "mean_deaths", "median_deaths",
"mean_retail", "median_retail", "mean_grocery", "median_grocery", "mean_parks", "median_parks", "mean_transit",
"median_transit", "mean_work", "median_work", "mean_res", "median_res")) %>%
na.omit() # drops count from 2766 to 2689. something to look into?
df_agg$case_diff_7_8 = df_agg$end_cases_8/df_agg$end_cases_7 - 1
df_agg$case_diff_7_8[is.na(df_agg$case_diff_7_8)] = df_agg$end_cases_8[is.na(df_agg$case_diff_7_8)] - 1
# Hardcoded county median as response variable cutoff but could be an arbitrary value
cutoff = 0.3409769
df_agg$high_growth_8 = factor(ifelse(df_agg$case_diff_7_8 > cutoff,'high_growth','low_growth'))
df_agg$high_growth_8 = relevel(df_agg$high_growth_8,ref='low_growth')
df_agg$retail_diff_7_8 = (df_agg$median_retail_8 - df_agg$median_retail_7)
df_agg$grocery_diff_7_8 = (df_agg$median_grocery_8 - df_agg$median_grocery_7)
df_agg$parks_diff_7_8 = (df_agg$median_parks_8 - df_agg$median_parks_7)
df_agg$transit_diff_7_8 = (df_agg$median_transit_8 - df_agg$median_transit_7)
df_agg$work_diff_7_8 = (df_agg$median_work_8 - df_agg$median_work_7)
df_agg$res_diff_7_8 = (df_agg$median_res_8 - df_agg$median_res_7)
# df_agg$ind_retail = as.factor(df_agg$median_retail_8 > median(df_agg$median_retail_8))
# df_agg$ind_grocery = as.factor(df_agg$median_grocery_8 > median(df_agg$median_grocery_8))
# df_agg$ind_parks = as.factor(df_agg$median_parks_8 > median(df_agg$median_parks_8))
# df_agg$ind_transit = as.factor(df_agg$median_transit_8 > median(df_agg$median_transit_8))
# df_agg$ind_work = as.factor(df_agg$median_work_8 > median(df_agg$median_work_8))
# df_agg$ind_res = as.factor(df_agg$median_res_8 > median(df_agg$median_res_8))
anyNA(df_agg)
# Bad dumb model 1
lm1 = lm(case_diff_7_8~population+mean_retail_7+mean_grocery_7+mean_parks_7+mean_transit_7+mean_work_7+mean_res_7,df_agg)
summary(lm1)
plot(lm1)
train.control = trainControl(method="cv",number=10)
step.model <- train(case_diff_7_8 ~ population + retail_diff_7_8 + grocery_diff_7_8 + parks_diff_7_8
+ transit_diff_7_8 + work_diff_7_8 + res_diff_7_8 + mean_retail_8 + mean_grocery_8
+ mean_parks_8 + mean_transit_8 + mean_work_8 + mean_res_8,
data = df_agg,
method = "leapBackward",
#tuneGrid = data.frame(nvmax = 1:5),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
coef(step.model$finalModel, id=nrow(summary(step.model)$which))
# Save some stepwise objects for quick reference
stepwise = as.data.frame(summary(step.model)$which)
stepwise_names = tail(names(stepwise[,stepwise[nrow(stepwise),]==TRUE]),-1)
stepwise_formula = as.formula(paste('case_diff_7_8~',paste(stepwise_names,collapse="+"),sep=""))
stepwise_lm = lm(stepwise_formula,data=df_agg)
summary(stepwise_lm)
# Train experimental classifiers and check performance
set.seed(1)
train_experimental = trainControl(method="cv",number=10,classProbs=TRUE,savePredictions=TRUE)
experimental = train(high_growth_8 ~ population + retail_diff_7_8 + grocery_diff_7_8 + parks_diff_7_8
+ transit_diff_7_8 + work_diff_7_8 + res_diff_7_8 + mean_retail_8 + mean_grocery_8
+ mean_parks_8 + mean_transit_8 + mean_work_8 + mean_res_8,
data = df_agg,
method = 'glmStepAIC',
trControl = train_experimental
)
summary(experimental)
# Get confusion matrix stats
confusionMatrix(experimental)
precision = confusionMatrix(experimental)$table[2,2]/sum(confusionMatrix(experimental)$table[2,])
recall = confusionMatrix(experimental)$table[2,2]/sum(confusionMatrix(experimental)$table[,2])
precision;recall
# Get ROC stats
roc_curve = roc(experimental$pred$obs,experimental$pred$high_growth)
plot(roc_curve)
roc_curve$auc
# Get calibration stats
calibration = calibration(experimental$pred$obs~experimental$pred$high_growth,cuts=5,class='high_growth')
xyplot(calibration)
df_agg_OOT = df_subset_OOT %>%
mutate(month = month(date)) %>%
group_by(nation,state,county,location_combined,fips,month, population) %>%
summarise(#mean_pop = mean(population, na.rm=TRUE),
#med_pop = median(population, na.rm=TRUE),
end_cases = last(cases,order_by=date),
mean_cases = mean(cases, na.rm=TRUE),
median_cases = median(cases, na.rm=TRUE),
end_deaths = last(deaths,order_by=date),
mean_deaths = mean(deaths, na.rm=TRUE),
median_deaths = median(deaths, na.rm=TRUE),
mean_retail = mean(mobility_retail_recreation_change, na.rm=TRUE),
median_retail = median(mobility_retail_recreation_change, na.rm=TRUE),
mean_grocery = mean(mobility_grocery_pharmacy_change, na.rm=TRUE),
median_grocery = median(mobility_grocery_pharmacy_change, na.rm=TRUE),
mean_parks = mean(mobility_parks_change, na.rm=TRUE),
median_parks = median(mobility_parks_change, na.rm=TRUE),
mean_transit = mean(mobility_transit_stations_change, na.rm=TRUE),
median_transit = median(mobility_transit_stations_change, na.rm=TRUE),
mean_work = mean(mobility_workplaces_change, na.rm=TRUE),
median_work = median(mobility_workplaces_change, na.rm=TRUE),
mean_res = mean(mobility_residential_change, na.rm=TRUE),
median_res = median(mobility_residential_change, na.rm=TRUE)
) %>%
# mutate(end_cases = ifelse(is.na(end_cases),0,end_cases),
#        mean_cases = ifelse(is.na(mean_cases),0,mean_cases),
#        median_cases = ifelse(is.na(median_cases),0,median_cases),
#        end_deaths = ifelse(is.na(end_deaths),0,end_deaths),
#        mean_deaths = ifelse(is.na(mean_deaths),0,mean_deaths),
#        median_deaths = ifelse(is.na(median_deaths),0,median_deaths),
#        mean_retail = ifelse(is.na(mean_retail),0,mean_retail),
#        median_retail = ifelse(is.na(median_retail),0,median_retail),
#        mean_grocery = ifelse(is.na(mean_grocery),0,mean_grocery),
#        median_grocery = ifelse(is.na(median_grocery),0,median_grocery),
#        mean_parks = ifelse(is.na(mean_parks),0,mean_parks),
#        median_parks = ifelse(is.na(median_parks),0,median_parks),
#        mean_transit = ifelse(is.na(mean_transit),0,mean_transit),
#        median_transit = ifelse(is.na(median_transit),0,median_transit),
#        mean_work = ifelse(is.na(mean_work),0,mean_work),
#        median_work = ifelse(is.na(median_work),0,median_work),
#        mean_res = ifelse(is.na(mean_res),0,mean_res),
#        median_res = ifelse(is.na(median_res),0,median_res)
#        ) %>%
pivot_wider(id_cols=c("nation","state","county","location_combined","fips", "population"),
names_from=c("month"),
values_from=c(#"mean_pop", "med_pop",
"end_cases", "mean_cases", "median_cases", "end_deaths", "mean_deaths", "median_deaths",
"mean_retail", "median_retail", "mean_grocery", "median_grocery", "mean_parks", "median_parks", "mean_transit",
"median_transit", "mean_work", "median_work", "mean_res", "median_res")) %>%
na.omit() # drops count from 2766 to 2689. something to look into?
df_agg_OOT$case_diff_7_8 = df_agg_OOT$end_cases_9/df_agg_OOT$end_cases_8 - 1
df_agg_OOT$case_diff_7_8 = df_agg_OOT$end_cases_9/df_agg_OOT$end_cases_8 - 1
df_agg_OOT
df_agg_OOT['case_diff_7_8']
df_agg_OOT$case_diff_7_8[is.na(df_agg_OOT$case_diff_7_8)] = df_agg_OOT$end_cases_9[is.na(df_agg_OOT$case_diff_7_8)] - 1
cutoff = 0.3409769
df_agg_OOT$high_growth_8 = factor(ifelse(df_agg_OOT$case_diff_7_8 > cutoff,'high_growth','low_growth'))
df_agg_OOT$high_growth_8 = relevel(df_agg_OOT$high_growth_8,ref='low_growth')
df_agg_OOT$retail_diff_7_8 = (df_agg_OOT$median_retail_9 - df_agg_OOT$median_retail_8)
df_agg_OOT$grocery_diff_7_8 = (df_agg_OOT$median_grocery_9 - df_agg_OOT$median_grocery_8)
df_agg_OOT$parks_diff_7_8 = (df_agg_OOT$median_parks_9 - df_agg_OOT$median_parks_8)
df_agg_OOT$transit_diff_7_8 = (df_agg_OOT$median_transit_9 - df_agg_OOT$median_transit_8)
df_agg_OOT$work_diff_7_8 = (df_agg_OOT$median_work_9 - df_agg_OOT$median_work_8)
df_agg_OOT$res_diff_7_8 = (df_agg_OOT$median_res_9 - df_agg_OOT$median_res_8)
# df_agg$ind_retail = as.factor(df_agg$median_retail_8 > median(df_agg$median_retail_8))
# df_agg$ind_grocery = as.factor(df_agg$median_grocery_8 > median(df_agg$median_grocery_8))
# df_agg$ind_parks = as.factor(df_agg$median_parks_8 > median(df_agg$median_parks_8))
# df_agg$ind_transit = as.factor(df_agg$median_transit_8 > median(df_agg$median_transit_8))
# df_agg$ind_work = as.factor(df_agg$median_work_8 > median(df_agg$median_work_8))
# df_agg$ind_res = as.factor(df_agg$median_res_8 > median(df_agg$median_res_8))
anyNA(df_agg_OOT)
predict(experimental,newdata=df_agg_OOT)
test_preds = predict(experimental,newdata=df_agg_OOT)
head(df_agg_OOT)
head(df_agg_OOT['high_growth_8'])
df_agg_OOT['high_growth_8']
test_preds
length(test_preds)
length(df_agg_OOT['high_growth_8'])
df_agg_OOT['high_growth_8']
cbind(df_agg_OOT,test_preds)
newtable = cbind(df_agg_OOT,test_preds)
names(newtable)
newtable['...87']
test_preds
names(test_preds)
names(test_preds) = 'test_preds'
newtable = cbind(df_agg_OOT,test_preds)
names(newtable)
names(newtable)[-1]
names(newtable)[87]
names(newtable)[87] = 'test_preds'
names(newtable)
table(newtable['high_growth_8'],newtable['test_preds'])
?confusionMatrix
confusionMatrix(newtable['high_growth_8'],newtable['test_preds'])
newtable['high_growth_8']
newtable['test_preds']
conf_mat(newtable, high_growth_8, test_preds)
??conf_mat
require(dplyr)
conf_mat(newtable, high_growth_8, test_preds)
install.packages("yardstick")
require(yardstick)
?precision()
conf_mat(newtable, high_growth_8, test_preds)
caret::confusionMatrix(newtable['high_growth_8'],newtable['test_preds'])
?confusionMatrix
caret::confusionMatrix(data=newtable['test_preds'],reference = newtable['high_growth_8'])
class(newtable['test_preds'])
as.factor(newtable['test_preds'])
newtable['test_preds']
as.factor(newtable['high_growth_8'])
factor(newtable['high_growth_8'])
df_agg_OOT$high_growth_8
caret::confusionMatrix(data=test_preds,reference = df_agg_OOT$high_growth_8)
# Get confusion matrix stats
confusionMatrix(experimental)
caret::confusionMatrix(data=test_preds,reference = df_agg_OOT$high_growth_8,positive='high_growth')
caret::confusionMatrix(data=test_preds,reference = df_agg_OOT$high_growth_8,positive='high_growth')$table[2,2]
CM_OOT = caret::confusionMatrix(data=test_preds,reference = df_agg_OOT$high_growth_8,positive='high_growth')
CM_OOT
precision_OOT = CM_OOT$table[2,2]/sum(CM_OOT$table[2,])
recall_OOT = CM_OOT$table[2,2]/sum(CM_OOT$table[,2])
precision_OOT;recall_OOT
precision
recall
experimental$pred$obs
?roc()
roc_curve_OOT = roc(df_agg_OOT$high_growth_8,test_preds)
?predict()
test_preds_terms = predict(experimental,newdata=df_agg_OOT,type='terms')
test_preds_terms = predict(experimental,newdata=df_agg_OOT,type='prob')
test_preds_terms
test_preds_probs = predict(experimental,newdata=df_agg_OOT,type='prob')
experimental$pred$obs
experimental$pred$high_growth
test_preds_probs
roc_curve_OOT = roc(df_agg_OOT$high_growth_8,test_preds_probs$high_growth)
plot(roc_curve_OOT)
roc_curve_OOT$auc
# Get calibration stats
calibration = calibration(df_agg_OOT$high_growth_8~est_preds_probs$high_growth,cuts=5,class='high_growth')
# Get calibration stats
calibration = calibration(df_agg_OOT$high_growth_8~test_preds_probs$high_growth,cuts=5,class='high_growth')
# Get calibration stats
calibration = calibration(experimental$pred$obs~experimental$pred$high_growth,cuts=5,class='high_growth')
xyplot(calibration)
# Get calibration stats
calibration_test = calibration(df_agg_OOT$high_growth_8~test_preds_probs$high_growth,cuts=5,class='high_growth')
xyplot(calibration_test)
df_agg_OOT$case_diff_7_8 = df_agg_OOT$end_cases_10/df_agg_OOT$end_cases_9 - 1
df_agg_OOT$case_diff_7_8[is.na(df_agg_OOT$case_diff_7_8)] = df_agg_OOT$end_cases_10[is.na(df_agg_OOT$case_diff_7_8)] - 1
df_agg_OOT$high_growth_8 = factor(ifelse(df_agg_OOT$case_diff_7_8 > cutoff,'high_growth','low_growth'))
df_agg_OOT$high_growth_8 = relevel(df_agg_OOT$high_growth_8,ref='low_growth')
df_agg_OOT$high_growth_8 = factor(ifelse(df_agg_OOT$case_diff_7_8 > cutoff,'high_growth','low_growth'))
df_agg_OOT$high_growth_8 = relevel(df_agg_OOT$high_growth_8,ref='low_growth')
df_agg_OOT$retail_diff_7_8 = (df_agg_OOT$median_retail_10 - df_agg_OOT$median_retail_9)
df_agg_OOT$grocery_diff_7_8 = (df_agg_OOT$median_grocery_10 - df_agg_OOT$median_grocery_9)
df_agg_OOT$parks_diff_7_8 = (df_agg_OOT$median_parks_10 - df_agg_OOT$median_parks_9)
df_agg_OOT$transit_diff_7_8 = (df_agg_OOT$median_transit_10 - df_agg_OOT$median_transit_9)
df_agg_OOT$work_diff_7_8 = (df_agg_OOT$median_work_10 - df_agg_OOT$median_work_9)
df_agg_OOT$res_diff_7_8 = (df_agg_OOT$median_res_10 - df_agg_OOT$median_res_9)
anyNA(df_agg_OOT)
test_preds = predict(experimental,newdata=df_agg_OOT)
test_preds_probs = predict(experimental,newdata=df_agg_OOT,type='prob')
newtable = cbind(df_agg_OOT,test_preds)
names(newtable)[87] = 'test_preds'
CM_OOT = caret::confusionMatrix(data=test_preds,reference = df_agg_OOT$high_growth_8,positive='high_growth')
precision_OOT = CM_OOT$table[2,2]/sum(CM_OOT$table[2,])
recall_OOT = CM_OOT$table[2,2]/sum(CM_OOT$table[,2])
precision_OOT;recall_OOT
roc_curve_OOT = roc(df_agg_OOT$high_growth_8,test_preds_probs$high_growth)
plot(roc_curve_OOT)
roc_curve_OOT$auc
# Get calibration stats
calibration_test = calibration(df_agg_OOT$high_growth_8~test_preds_probs$high_growth,cuts=5,class='high_growth')
xyplot(calibration_test)
